import streamlit as st
import google.generativeai as genai
import pandas as pd

st.set_page_config(page_title="Gemini Chatbot with CSV", layout="centered")

try:
    key = st.secrets['gemini_api_key']
    genai.configure(api_key=key)
    model = genai.GenerativeModel('gemini-2.0-flash-lite')

    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° session state
    if "chat" not in st.session_state:
        st.session_state.chat = model.start_chat(history=[])
    if "df" not in st.session_state:
        st.session_state.df = None
    if "df_name" not in st.session_state:
        st.session_state.df_name = "uploaded_df"

    st.title("üìä Gemini Pro Chatbot + CSV Analyzer")

    # ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå CSV
    uploaded_file = st.file_uploader("üìÇ Upload CSV file to analyze", type="csv")
    if uploaded_file:
        st.session_state.df = pd.read_csv(uploaded_file)
        st.success("‚úÖ File uploaded successfully!")
        st.write("üîç Sample Data:")
        st.dataframe(st.session_state.df.head())

    # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏õ‡∏•‡∏á role
    def role_to_streamlit(role: str) -> str:
        return 'assistant' if role == 'model' else role

    # ‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÅ‡∏ä‡∏ó
    for message in st.session_state.chat.history:
        with st.chat_message(role_to_streamlit(message.role)):
            st.markdown(message.parts[0].text)

    # ‡∏Å‡∏•‡πà‡∏≠‡∏á‡πÅ‡∏ä‡∏ó
    if prompt := st.chat_input("üí¨ Ask about your data or anything..."):

        # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏¢‡∏π‡πà ‡∏Å‡πá‡πÅ‡∏ô‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô prompt
        if st.session_state.df is not None:
            df = st.session_state.df
            df_name = st.session_state.df_name
            example_record = df.head(3).to_string()
            full_prompt = f"""
The user uploaded a DataFrame named `{df_name}`. Below are the first 3 rows:

{example_record}

Now answer the user's question based on this data:

{prompt}
"""
        else:
            full_prompt = prompt

        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
        st.chat_message("user").markdown(prompt)

        # ‡∏™‡πà‡∏á prompt ‡πÑ‡∏õ‡πÉ‡∏´‡πâ Gemini
        response = st.session_state.chat.send_message(full_prompt)

        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
        with st.chat_message("assistant"):
            st.markdown(response.text)

except Exception as e:
    st.error(f"An error occurred: {e}")
